{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033b278b",
   "metadata": {},
   "source": [
    "# Multi Model Processing\n",
    "\n",
    "Is the ability for the model to understand, analyse and generate information across multiple modalities, such as text, images, and audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8c7b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diogo/miniconda3/envs/vertexai_env/lib/python3.9/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI initialized\n"
     ]
    }
   ],
   "source": [
    "import vertexai_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41df7a3",
   "metadata": {},
   "source": [
    "# Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c930e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.generative_models import GenerativeModel\n",
    "from vertexai.generative_models import Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5aa4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/fruit.png\"\n",
    "image_file = Part.from_uri(url,mime_type=\"image/png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be70332f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"Here are the fruits in the image:\\n\\n*   Strawberries: 2\\n*   Flat peach: 1\\n*   Lemon: 1\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  avg_logprobs: -1.8912439653950353\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 1305\n",
       "  candidates_token_count: 31\n",
       "  total_token_count: 1664\n",
       "  prompt_tokens_details {\n",
       "    modality: IMAGE\n",
       "    token_count: 1290\n",
       "  }\n",
       "  prompt_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 15\n",
       "  }\n",
       "  candidates_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 31\n",
       "  }\n",
       "  thoughts_token_count: 328\n",
       "}\n",
       "model_version: \"gemini-2.5-flash\"\n",
       "create_time {\n",
       "  seconds: 1756886826\n",
       "  nanos: 290173000\n",
       "}\n",
       "response_id: \"Kve3aP3aEYuBm9IPyqSKEQ\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GenerativeModel(\"gemini-2.5-flash\")\n",
    "prompt = \"List and count all fruits in the image in bullet points in few words.\"\n",
    "model.generate_content([image_file, prompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb3b3d",
   "metadata": {},
   "source": [
    "# Multiple image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b83ad33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"Colorful wooden blocks are arranged into an abstract structure in one image, and neatly stacked into a pyramid in the other.\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  avg_logprobs: -11.042838718580162\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 524\n",
       "  candidates_token_count: 23\n",
       "  total_token_count: 1336\n",
       "  prompt_tokens_details {\n",
       "    modality: IMAGE\n",
       "    token_count: 516\n",
       "  }\n",
       "  prompt_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 8\n",
       "  }\n",
       "  candidates_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 23\n",
       "  }\n",
       "  thoughts_token_count: 789\n",
       "}\n",
       "model_version: \"gemini-2.5-flash\"\n",
       "create_time {\n",
       "  seconds: 1756887536\n",
       "  nanos: 785440000\n",
       "}\n",
       "response_id: \"8Pm3aKD4L5CVmecPyqPo6AI\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_block1 = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/blocks-1.jpg\"\n",
    "url_block2 = \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/blocks-2.jpg\"\n",
    "image_file_block1 = Part.from_uri(url_block1,mime_type=\"image/jpg\")\n",
    "image_file_block2 = Part.from_uri(url_block2,mime_type=\"image/jpg\")\n",
    "prompt = \"Describe both images in just one sentence.\"\n",
    "model.generate_content([image_file_block1,image_file_block2,prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fff40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vertexai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
